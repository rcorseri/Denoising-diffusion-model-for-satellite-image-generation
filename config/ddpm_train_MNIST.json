{
    "name": "MNIST",
    "phase": "train", // train (train+val) or test
    "distributed": false,
    "gpu_ids": [
        0
    ],
    "path": { //set the path
        "log": "logs",
        "tb_logger": "tb_logger",
        "results": "results",
        "checkpoint": "checkpoint",
        //"resume_state": null
        "resume_state": "experiments/MNIST_240516_111414/checkpoint/I30000_E938"
    },
    "datasets": {
        "train": {
            "name": "TEST", // Options: "LEVIR-WHU-DSIFN", "Million-AID"
            "dataroot": "datasets/MNIST/trainingSet", // Options: "dataset/LEVIR-WHU-DSIFN", "dataset/Million-AID"
            "resolution": 28, // high resolution
            "batch_size": 16,
            "num_workers": 4,
            "use_shuffle": true,
            "data_len": 500 // -1 represents all data used in train
        },
        "val": {
            "name": "MNIST", // Options: "LEVIR-CD-256", "Million-AID"
            "resolution": 28,
            "data_len": 2
        }
    },
    "model": {
        "which_model_G": "sr3", // use the ddpm or sr3 network structure
        "finetune_norm": false,
        "unet": {
            "in_channel": 3,
            "out_channel": 3,
            "inner_channel": 64,
            "channel_multiplier": [1,2,8],
            "attn_res": [16],
            "res_blocks": 2,
            "dropout": 0.2
        },
        "beta_schedule": { // use munual beta_schedule for acceleration
            "train": {
                "schedule": "cosine",
                "n_timestep": 2000,
                "linear_start": 1e-6,
                "linear_end": 1e-2
            },
            "val": {
                "schedule": "cosine",
                "n_timestep": 2000,
                "linear_start": 1e-6,
                "linear_end": 1e-2
            }
        },
        "diffusion": {
            "image_size": 28,
            "channels": 3, //sample channel
            "loss": "l2", //options "l1" or "l2"
            "conditional": false // unconditional generation or unconditional generation(super_resolution)
        }
    },
    "train": {
        "n_iter": 1000000,
        "val_freq": 10000,
        "save_checkpoint_freq": 1e4,
        "print_freq":1000 ,
        "optimizer": {
            "type": "adamw",
            "lr": 1e-4
        },
        "ema_scheduler": { // not used now
            "step_start_ema": 5000,
            "update_ema_every": 1,
            "ema_decay": 0.9999
        }
    },
    "wandb": {
        "project": "TEST"
    }
}
